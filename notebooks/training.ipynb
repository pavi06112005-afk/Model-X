{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af98a3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (195196, 32)\n",
      "Target: DEMENTIA (0 = No, 1 = Yes)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NACCID</th>\n",
       "      <th>VISITMO</th>\n",
       "      <th>VISITDAY</th>\n",
       "      <th>VISITYR</th>\n",
       "      <th>BIRTHMO</th>\n",
       "      <th>BIRTHYR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>HISPANIC</th>\n",
       "      <th>RACE</th>\n",
       "      <th>PRIMLANG</th>\n",
       "      <th>...</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>NACCADC</th>\n",
       "      <th>FORMVER</th>\n",
       "      <th>NACCDAYS</th>\n",
       "      <th>NACCFDYS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BMI</th>\n",
       "      <th>EVER_SMOKER</th>\n",
       "      <th>EDUC_YEARS</th>\n",
       "      <th>DEMENTIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NACC002909</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>1952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>232.0</td>\n",
       "      <td>186</td>\n",
       "      <td>3.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>32.353898</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NACC002909</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>1952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>186</td>\n",
       "      <td>3.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>71</td>\n",
       "      <td>30.680421</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NACC003487</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>1956</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>175.0</td>\n",
       "      <td>186</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>23.731674</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NACC004352</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1958</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>888.0</td>\n",
       "      <td>186</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NACC004687</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>1945</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>186</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77</td>\n",
       "      <td>18.968521</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NACCID  VISITMO  VISITDAY  VISITYR  BIRTHMO  BIRTHYR  SEX  HISPANIC  \\\n",
       "0  NACC002909       12        28     2022        5     1952    1         0   \n",
       "1  NACC002909        1        23     2024        5     1952    1         0   \n",
       "2  NACC003487       11        15     2023       12     1956    1         0   \n",
       "3  NACC004352       10         5     2021        1     1958    2         1   \n",
       "4  NACC004687       11        14     2022        2     1945    1         1   \n",
       "\n",
       "   RACE  PRIMLANG  ...  WEIGHT  NACCADC  FORMVER  NACCDAYS  NACCFDYS  AGE  \\\n",
       "0     1         1  ...   232.0      186      3.0     391.0       0.0   70   \n",
       "1     1         1  ...   220.0      186      3.0     391.0     391.0   71   \n",
       "2     1         1  ...   175.0      186      3.0       0.0       0.0   66   \n",
       "3     1         2  ...   888.0      186      3.0       0.0       0.0   63   \n",
       "4     1         1  ...   114.0      186      3.0       0.0       0.0   77   \n",
       "\n",
       "         BMI  EVER_SMOKER  EDUC_YEARS  DEMENTIA  \n",
       "0  32.353898            0          16         0  \n",
       "1  30.680421            0          16         0  \n",
       "2  23.731674            0          16         0  \n",
       "3  79.166667            0          16         8  \n",
       "4  18.968521            0          12         0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELL 1: Load processed data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/processed_clean_non_medical.csv\")\n",
    "print(f\"Loaded: {df.shape}\")\n",
    "print(\"Target: DEMENTIA (0 = No, 1 = Yes)\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b0f7d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (156156, 30), Test: (39040, 30)\n",
      "Dementia rate: 203.7%\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Split + Impute\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Features & target\n",
    "X = df.drop(columns=['NACCID', 'DEMENTIA'])\n",
    "y = df['DEMENTIA']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Impute missing with median (robust)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "X_test_imp = imputer.transform(X_test)\n",
    "\n",
    "print(f\"Train: {X_train_imp.shape}, Test: {X_test_imp.shape}\")\n",
    "print(f\"Dementia rate: {y.mean():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d91c8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PAVISHANTH\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multi_class must be in ('ovo', 'ovr')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m model.fit(X_train_imp, y_train)\n\u001b[32m     17\u001b[39m y_pred_proba = model.predict_proba(X_test_imp)[:, \u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m auc = \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_proba\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m results[name] = auc\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: AUC = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_ranking.py:679\u001b[39m, in \u001b[36mroc_auc_score\u001b[39m\u001b[34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[39m\n\u001b[32m    672\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    673\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPartial AUC computation not available in \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    674\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmulticlass setting, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmax_fpr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    675\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m set to `None`, received `max_fpr=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    676\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33minstead\u001b[39m\u001b[33m\"\u001b[39m.format(max_fpr)\n\u001b[32m    677\u001b[39m         )\n\u001b[32m    678\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m multi_class == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mmulti_class must be in (\u001b[39m\u001b[33m'\u001b[39m\u001b[33movo\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33movr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _multiclass_roc_auc_score(\n\u001b[32m    681\u001b[39m         y_true, y_score, labels, multi_class, average, sample_weight\n\u001b[32m    682\u001b[39m     )\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: multi_class must be in ('ovo', 'ovr')"
     ]
    }
   ],
   "source": [
    "# CELL 3: Train Logistic, Random Forest, XGBoost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_imp, y_train)\n",
    "    y_pred_proba = model.predict_proba(X_test_imp)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results[name] = auc\n",
    "    print(f\"{name}: AUC = {auc:.4f}\")\n",
    "\n",
    "# Plot AUC\n",
    "plt.bar(results.keys(), results.values())\n",
    "plt.ylim(0.5, 0.9)\n",
    "plt.title(\"Model Comparison (AUC)\")\n",
    "plt.ylabel(\"AUC Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f346449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: Use XGBoost (usually best) + Calibrate\n",
    "best_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "best_model.fit(X_train_imp, y_train)\n",
    "\n",
    "# Calibrate probabilities (more accurate %)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "calibrated = CalibratedClassifierCV(best_model, method='sigmoid', cv='prefit')\n",
    "calibrated.fit(X_train_imp, y_train)\n",
    "\n",
    "y_pred_proba = calibrated.predict_proba(X_test_imp)[:, 1]\n",
    "final_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Calibrated XGBoost AUC: {final_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9975faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: Predict function\n",
    "def predict_dementia_risk(person_dict):\n",
    "    # Convert to DataFrame\n",
    "    person_df = pd.DataFrame([person_dict])\n",
    "    \n",
    "    # Align columns with training data\n",
    "    person_aligned = person_df.reindex(columns=X.columns, fill_value=0)\n",
    "    \n",
    "    # Impute\n",
    "    person_imp = imputer.transform(person_aligned)\n",
    "    \n",
    "    # Predict probability\n",
    "    risk_prob = calibrated.predict_proba(person_imp)[0, 1]\n",
    "    risk_percent = risk_prob * 100\n",
    "    \n",
    "    print(f\"Dementia Risk: {risk_percent:.1f}%\")\n",
    "    return risk_percent\n",
    "\n",
    "# Example: 75-year-old female, low education, smoker, high BMI\n",
    "example = {\n",
    "    'AGE': 75,\n",
    "    'SEX': 2,           # 2 = Female\n",
    "    'EDUC_YEARS': 8,\n",
    "    'EVER_SMOKER': 1,\n",
    "    'BMI': 30,\n",
    "    'ALCOHOL_FREQ': 0,\n",
    "    'INDEPEND': 1,\n",
    "    'MARISTAT': 1       # Married\n",
    "}\n",
    "predict_dementia_risk(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367ec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: SHAP (install once: pip install shap)\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "explainer = shap.Explainer(calibrated)\n",
    "shap_values = explainer(X_test_imp)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", max_display=10)\n",
    "plt.title(\"Top 10 Features Driving Dementia Risk\")\n",
    "plt.show()\n",
    "\n",
    "# For one person\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values.values[0,:], X_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07107149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: Save model\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(calibrated, \"models/dementia_risk_model.pkl\")\n",
    "joblib.dump(imputer, \"models/imputer.pkl\")\n",
    "joblib.dump(X.columns.tolist(), \"models/feature_columns.pkl\")\n",
    "\n",
    "print(\"Model saved: models/dementia_risk_model.pkl\")\n",
    "\n",
    "# Git commit\n",
    "!git add .\n",
    "!git commit -m \"feat: train XGBoost + calibrate + SHAP + predict function\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ea026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8: Print results for report\n",
    "print(\"=== HACKATHON RESULTS ===\")\n",
    "print(f\"Best Model: Calibrated XGBoost\")\n",
    "print(f\"Test AUC: {final_auc:.4f}\")\n",
    "print(f\"Top Features: AGE, EDUC_YEARS, EVER_SMOKER, BMI\")\n",
    "print(f\"Model saved and versioned in Git\")\n",
    "print(f\"GitHub: https://github.com/yourusername/dementia-risk-hackathon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# CELL 1 – Load cleaned data\n",
    "# -------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "DATA_PATH = \"../data/processed_clean_non_medical.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Rows: {df.shape[0]:,},  Columns: {df.shape[1]}\")\n",
    "print(\"Target column → DEMENTIA (0/1)\")\n",
    "\n",
    "# Keep a copy of the ID column (optional, will be dropped later)\n",
    "ids = df[\"NACCID\"].copy()\n",
    "X_raw = df.drop(columns=[\"NACCID\", \"DEMENTIA\"])\n",
    "y = df[\"DEMENTIA\"]\n",
    "\n",
    "print(f\"Dementia prevalence: {y.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# CELL 2 – Split, impute & scale\n",
    "# -------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X_raw, y, ids, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Pipeline: impute median → standard-scale\n",
    "preprocess = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\",  StandardScaler())\n",
    "])\n",
    "\n",
    "X_train_prep = preprocess.fit_transform(X_train)\n",
    "X_test_prep  = preprocess.transform(X_test)\n",
    "\n",
    "print(f\"Train shape: {X_train_prep.shape}, Test shape: {X_test_prep.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b584792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# CELL 3 – Train & compare AUC\n",
    "# -------------------------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = {\n",
    "    \"Logistic\": LogisticRegression(max_iter=2000, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200,\n",
    "                                          max_depth=None,\n",
    "                                          random_state=42,\n",
    "                                          n_jobs=-1),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False,\n",
    "                             eval_metric=\"logloss\",\n",
    "                             n_estimators=300,\n",
    "                             learning_rate=0.05,\n",
    "                             max_depth=6,\n",
    "                             subsample=0.8,\n",
    "                             colsample_bytree=0.8,\n",
    "                             random_state=42,\n",
    "                             n_jobs=-1)\n",
    "}\n",
    "\n",
    "aucs = {}\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_train_prep, y_train)\n",
    "    proba = clf.predict_proba(X_test_prep)[:, 1]\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    aucs[name] = auc\n",
    "    print(f\"{name:12} → AUC = {auc:.4f}\")\n",
    "\n",
    "# Bar chart\n",
    "plt.bar(aucs.keys(), aucs.values(), color=[\"#4C72B0\",\"#55A868\",\"#C44E52\"])\n",
    "plt.ylim(0.5, 0.9)\n",
    "plt.title(\"Model AUC Comparison\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707bdc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# CELL 4 – Calibrate XGBoost (or whichever is best)\n",
    "# -------------------------------------------------\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "best_raw = models[\"XGBoost\"]          # change name if another model wins\n",
    "calibrated = CalibratedClassifierCV(best_raw, method=\"sigmoid\", cv=\"prefit\")\n",
    "calibrated.fit(X_train_prep, y_train)\n",
    "\n",
    "cal_proba = calibrated.predict_proba(X_test_prep)[:, 1]\n",
    "cal_auc   = roc_auc_score(y_test, cal_proba)\n",
    "print(f\"Calibrated XGBoost AUC = {cal_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b971f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# CELL 5 – Prediction function (use it in the report)\n",
    "# -------------------------------------------------\n",
    "import json   # optional – save column order for later\n",
    "\n",
    "def dementia_risk_pct(person_dict: dict) -> float:\n",
    "    \"\"\"Input: dict with same column names as training data.\n",
    "       Output: risk % (0-100).\"\"\"\n",
    "    person = pd.DataFrame([person_dict])\n",
    "    person_aligned = person.reindex(columns=X_train.columns, fill_value=0)\n",
    "    person_prep = preprocess.transform(person_aligned)\n",
    "    prob = calibrated.predict_proba(person_prep)[0, 1]\n",
    "    return round(prob * 100, 1)\n",
    "\n",
    "# ---- Example -------------------------------------------------\n",
    "example = {\n",
    "    \"AGE\": 78,\n",
    "    \"SEX\": 2,               # 2 = Female\n",
    "    \"EDUC_YEARS\": 10,\n",
    "    \"EVER_SMOKER\": 1,\n",
    "    \"BMI\": 31.2,\n",
    "    \"ALCOHOL_FREQ\": 1,      # occasional\n",
    "    \"INDEPEND\": 1,\n",
    "    \"MARISTAT\": 1           # married\n",
    "}\n",
    "print(f\"Example risk → {dementia_risk_pct(example)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# CELL 6 – SHAP (install once: pip install shap)\n",
    "# -------------------------------------------------\n",
    "!pip install -q shap   # run only once\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "explainer = shap.Explainer(calibrated, X_train_prep, feature_names=X_train.columns)\n",
    "shap_vals = explainer(X_test_prep[:200])   # first 200 for speed\n",
    "\n",
    "# Summary bar\n",
    "shap.summary_plot(shap_vals, X_test.iloc[:200], plot_type=\"bar\", max_display=10)\n",
    "plt.title(\"Top 10 Features Driving Dementia Risk\")\n",
    "plt.show()\n",
    "\n",
    "# Force plot for the example person\n",
    "person_prep = preprocess.transform(\n",
    "    pd.DataFrame([example]).reindex(columns=X_train.columns, fill_value=0)\n",
    ")\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, \n",
    "                explainer(person_prep).values[0],\n",
    "                X_test.iloc[0:1])   # just to show layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# CELL 7 – Persist artefacts\n",
    "# -------------------------------------------------\n",
    "import joblib, json, os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(calibrated, \"models/dementia_risk_model.pkl\")\n",
    "joblib.dump(preprocess, \"models/preprocess_pipeline.pkl\")\n",
    "json.dump(X_train.columns.tolist(), open(\"models/feature_columns.json\", \"w\"))\n",
    "\n",
    "print(\"All artefacts saved in ./models/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
